{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1 - Deep Learning with Pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Seed\n",
    "\n",
    "This is a way to make random predictable, look at this code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "5\n",
      "2\n",
      "10\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.seed(9001)\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now hold on a second and look at this next example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "5\n",
      "2\n",
      "10\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.seed(9001)\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))\n",
    "\n",
    "print(random.randint(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what happenned here? How did this randomly generated numbers come out EXACTLY the same? \n",
    "\n",
    "This is because we applied the `random.seed()` command. \n",
    "\n",
    "This command allows to set the same sequence of random numbers. And this is exactly the same in Pytorch!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4963, 0.7682])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "print(torch.rand(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multiplying matrices \n",
    "\n",
    "You can multiply tensors by:\n",
    "1. Using * command\n",
    "2. Using torch.mm command \n",
    "\n",
    "If we multiplied two matrices: (64, 784) * (784, 256) => (64, 256) \n",
    "Note that the 784 parameter has to be the same because of that we are always going to shape the matrices around that idea. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = torch.rand((1, 5))\n",
    "weights = torch.rand((1, 5))\n",
    "\n",
    "\n",
    "first_option = torch.sum(features * weights)\n",
    "\n",
    "second_option = torch.mm(features, weights.view(5, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9591)\n",
      "tensor([[0.9591]])\n"
     ]
    }
   ],
   "source": [
    "print(first_option)\n",
    "print(second_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this two answers would've been different if we tried to view both of them, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = torch.rand((1, 5))\n",
    "weights = torch.rand((1, 5))\n",
    "\n",
    "\n",
    "first_option = torch.sum(features * weights.view(1, 5))\n",
    "\n",
    "second_option = torch.mm(features, weights.view(5, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3932)\n",
      "tensor([[1.3932]])\n"
     ]
    }
   ],
   "source": [
    "print(first_option)\n",
    "print(second_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Datasets\n",
    "\n",
    "`torchvision` is a helpful package that contains multiple datasets. \n",
    "\n",
    "Supposed Datasets include:\n",
    "1. MNIST\n",
    "2. Fashion-MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flattering \n",
    "\n",
    "-We could change the shape of a tensor \n",
    "\n",
    "This remove the dimensionality of the data to the new shape \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 1, 4, 1],\n",
       "        [3, 1, 3, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = torch.tensor([[[4, 1], [4, 1]], [[3, 1], [3, 2]]])\n",
    "\n",
    "flattered = images.view(images.shape[0], -1)\n",
    "\n",
    "flattered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Softmax\n",
    "\n",
    "Softmax gives us the probability of the classes gives images. Originally, the network is randomly initialized and therefore approaches random distribution. Softmax is commonly used in multi-class learning problems where a set of features can be related to one of K classes. \n",
    "\n",
    "The equation computes the normalized exponential function of all the units in the layer. \n",
    "\n",
    "It becomes interesting because we are dealing with 2D elements \n",
    "\n",
    "See: https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71828183,  7.3890561 , 20.08553692])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "my_list = [1, 2, 3]\n",
    "total = np.exp(my_list)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "my_list = torch.tensor([[1, 2], [1, 2], [1, 2]])\n",
    "total = np.exp(my_list)\n",
    "new = torch.sum(total, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.1073, 10.1073, 10.1073], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2689, 0.7311],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.2689, 0.7311]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total/new.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random with Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 8, 1, 9, 6, 1, 0, 2, 9, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "def flip_coin():\n",
    "    x = torch.rand(1)\n",
    "    if x > 0.5:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(flip_coin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0885])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(10).random_(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Numpy Tranpose vs view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 5 3]\n",
      " [2 6 2]\n",
      " [3 7 1]]\n",
      "---------\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [3]\n",
      " [2]\n",
      " [1]]\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "matrix = np.array([[1, 2, 3], \n",
    "         [5, 6, 7], \n",
    "         [3, 2, 1]])\n",
    "print(matrix.transpose())\n",
    "print(\"-\" * 9)\n",
    "print(matrix.reshape(9, 1))\n",
    "print(\"-\" * 9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Torchvision and transforms\n",
    "\n",
    "To resize element you could use `transforms.Resize(number)` \n",
    "\n",
    "However, in order to resize more than one elements we could send in a tuple \n",
    "\n",
    "`transforms.Resize((number1, number2))`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pretrained networks\n",
    "\n",
    "Taking an existing network that has already learned to extract powerful features and use it as a starting point to learn a new task. \n",
    "\n",
    "* It is important to think about the tradeoff between accuracy and speed \n",
    "* The number of layers tells us the amount of hidden layers (i.e. `densenet121` has 121 hidden layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelsheinman/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "model = models.densenet121(pretrained=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
